{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "021d65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86fab5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Genai_Projects\\ai_ecom_agent\\Data\\sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e2c8ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>super! great cooler excellent air flow and for...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awesome best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair the quality is good but the power of air ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>useless product very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment\n",
       "0  super! great cooler excellent air flow and for...  positive\n",
       "1      awesome best budget 2 fit cooler nice cooling  positive\n",
       "2  fair the quality is good but the power of air ...  positive\n",
       "3  useless product very bad product its a only a fan  negative\n",
       "4                                 fair ok ok product   neutral"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2de78933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205047</th>\n",
       "      <td>must buy! good product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205048</th>\n",
       "      <td>super! nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205049</th>\n",
       "      <td>nice very nice and fast delivery</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205050</th>\n",
       "      <td>just wow! awesome product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205051</th>\n",
       "      <td>value-for-money very good but mixing bowl not ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text Sentiment\n",
       "205047                             must buy! good product  positive\n",
       "205048                                        super! nice  positive\n",
       "205049                   nice very nice and fast delivery  positive\n",
       "205050                          just wow! awesome product  positive\n",
       "205051  value-for-money very good but mixing bowl not ...   neutral"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['product_name', 'product_price', 'Rate'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_price\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['product_name', 'product_price', 'Rate'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=[\"product_name\",\"product_price\",\"Rate\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a854be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>super!</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awesome</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>useless product</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205047</th>\n",
       "      <td>must buy!</td>\n",
       "      <td>good product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205048</th>\n",
       "      <td>super!</td>\n",
       "      <td>nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205049</th>\n",
       "      <td>nice</td>\n",
       "      <td>very nice and fast delivery</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205050</th>\n",
       "      <td>just wow!</td>\n",
       "      <td>awesome product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205051</th>\n",
       "      <td>value-for-money</td>\n",
       "      <td>very good but mixing bowl not included is one ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205052 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Review  ... Sentiment\n",
       "0                super!  ...  positive\n",
       "1               awesome  ...  positive\n",
       "2                  fair  ...  positive\n",
       "3       useless product  ...  negative\n",
       "4                  fair  ...   neutral\n",
       "...                 ...  ...       ...\n",
       "205047        must buy!  ...  positive\n",
       "205048           super!  ...  positive\n",
       "205049             nice  ...  positive\n",
       "205050        just wow!  ...  positive\n",
       "205051  value-for-money  ...   neutral\n",
       "\n",
       "[205052 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"Review\"].astype(str) + \" \" + df[\"Summary\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a873df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Review\",\"Summary\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05abf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>super! great cooler excellent air flow and for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>awesome best budget 2 fit cooler nice cooling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>fair the quality is good but the power of air ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>useless product very bad product its a only a fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>fair ok ok product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205047</th>\n",
       "      <td>positive</td>\n",
       "      <td>must buy! good product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205048</th>\n",
       "      <td>positive</td>\n",
       "      <td>super! nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205049</th>\n",
       "      <td>positive</td>\n",
       "      <td>nice very nice and fast delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205050</th>\n",
       "      <td>positive</td>\n",
       "      <td>just wow! awesome product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205051</th>\n",
       "      <td>neutral</td>\n",
       "      <td>value-for-money very good but mixing bowl not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205052 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                                               text\n",
       "0       positive  super! great cooler excellent air flow and for...\n",
       "1       positive      awesome best budget 2 fit cooler nice cooling\n",
       "2       positive  fair the quality is good but the power of air ...\n",
       "3       negative  useless product very bad product its a only a fan\n",
       "4        neutral                                 fair ok ok product\n",
       "...          ...                                                ...\n",
       "205047  positive                             must buy! good product\n",
       "205048  positive                                        super! nice\n",
       "205049  positive                   nice very nice and fast delivery\n",
       "205050  positive                          just wow! awesome product\n",
       "205051   neutral  value-for-money very good but mixing bowl not ...\n",
       "\n",
       "[205052 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7243cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"text\",\"Sentiment\"]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"D:\\Genai_Projects\\ai_ecom_agent\\Data\\sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf7ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>super! great cooler excellent air flow and for...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awesome best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fair the quality is good but the power of air ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>useless product very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205047</th>\n",
       "      <td>must buy! good product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205048</th>\n",
       "      <td>super! nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205049</th>\n",
       "      <td>nice very nice and fast delivery</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205050</th>\n",
       "      <td>just wow! awesome product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205051</th>\n",
       "      <td>value-for-money very good but mixing bowl not ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205052 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text Sentiment\n",
       "0       super! great cooler excellent air flow and for...  positive\n",
       "1           awesome best budget 2 fit cooler nice cooling  positive\n",
       "2       fair the quality is good but the power of air ...  positive\n",
       "3       useless product very bad product its a only a fan  negative\n",
       "4                                      fair ok ok product   neutral\n",
       "...                                                   ...       ...\n",
       "205047                             must buy! good product  positive\n",
       "205048                                        super! nice  positive\n",
       "205049                   nice very nice and fast delivery  positive\n",
       "205050                          just wow! awesome product  positive\n",
       "205051  value-for-money very good but mixing bowl not ...   neutral\n",
       "\n",
       "[205052 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eec754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)   \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "X = X.apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85b537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    super! great cooler excellent air flow and for...\n",
       "1        awesome best budget 2 fit cooler nice cooling\n",
       "2    fair the quality is good but the power of air ...\n",
       "3    useless product very bad product its a only a fan\n",
       "4                                   fair ok ok product\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17e146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         super great cooler excellent air flow and for ...\n",
       "1               awesome best budget fit cooler nice cooling\n",
       "2         fair the quality is good but the power of air ...\n",
       "3         useless product very bad product its a only a fan\n",
       "4                                        fair ok ok product\n",
       "                                ...                        \n",
       "205047                                must buy good product\n",
       "205048                                           super nice\n",
       "205049                     nice very nice and fast delivery\n",
       "205050                             just wow awesome product\n",
       "205051    value for money very good but mixing bowl not ...\n",
       "Name: text, Length: 205052, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe755b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e048ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')        # for tokenization\n",
    "nltk.download('punkt_tab')    # fixes \"punkt_tab\" error in newer NLTK versions\n",
    "nltk.download('stopwords')    # for removing stopwords\n",
    "nltk.download('wordnet')      # for lemmatization\n",
    "nltk.download('omw-1.4')      # for lemmatizer (WordNet data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4de1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def processing(text):\n",
    "    text = word_tokenize(text)                                \n",
    "    text = [word for word in text if word not in stop_words]  \n",
    "    text = [lemmatizer.lemmatize(word) for word in text]      \n",
    "    return text\n",
    "\n",
    "X = X.apply(processing)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14386ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [super, great, cooler, excellent, air, flow, p...\n",
       "1         [awesome, best, budget, fit, cooler, nice, coo...\n",
       "2                 [fair, quality, good, power, air, decent]\n",
       "3                     [useless, product, bad, product, fan]\n",
       "4                                   [fair, ok, ok, product]\n",
       "                                ...                        \n",
       "205047                           [must, buy, good, product]\n",
       "205048                                        [super, nice]\n",
       "205049                         [nice, nice, fast, delivery]\n",
       "205050                              [wow, awesome, product]\n",
       "205051    [value, money, good, mixing, bowl, included, o...\n",
       "Name: text, Length: 205052, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda tokens: \" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb106f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         super great cooler excellent air flow price am...\n",
       "1               awesome best budget fit cooler nice cooling\n",
       "2                        fair quality good power air decent\n",
       "3                           useless product bad product fan\n",
       "4                                        fair ok ok product\n",
       "                                ...                        \n",
       "205047                                must buy good product\n",
       "205048                                           super nice\n",
       "205049                              nice nice fast delivery\n",
       "205050                                  wow awesome product\n",
       "205051    value money good mixing bowl included one disa...\n",
       "Name: text, Length: 205052, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=42)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9205274759573181\n",
      "[[ 5802    76  1043]\n",
      " [  634   517  1400]\n",
      " [  755   166 40870]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.84      0.82      6921\n",
      "     neutral       0.68      0.20      0.31      2551\n",
      "    positive       0.94      0.98      0.96     41791\n",
      "\n",
      "    accuracy                           0.92     51263\n",
      "   macro avg       0.81      0.67      0.70     51263\n",
      "weighted avg       0.91      0.92      0.91     51263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred = mnb.predict(X_test)\n",
    "acc_score = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "matrix = confusion_matrix(y_pred=y_pred,y_true=y_test)\n",
    "report = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(\"accuracy\" , acc_score)\n",
    "print(matrix)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=42)\n",
    "vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(1,2))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66942ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8961824317734038\n",
      "[[ 6121   686   114]\n",
      " [  369  1899   283]\n",
      " [  694  3176 37921]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87      6921\n",
      "     neutral       0.33      0.74      0.46      2551\n",
      "    positive       0.99      0.91      0.95     41791\n",
      "\n",
      "    accuracy                           0.90     51263\n",
      "   macro avg       0.72      0.85      0.76     51263\n",
      "weighted avg       0.94      0.90      0.91     51263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(class_weight=\"balanced\")\n",
    "logistic.fit(X_train,y_train)\n",
    "y_pred = logistic.predict(X_test)\n",
    "acc_score = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "matrix = confusion_matrix(y_pred=y_pred,y_true=y_test)\n",
    "report = classification_report(y_pred=y_pred,y_true=y_test)\n",
    "print(\"accuracy\" , acc_score)\n",
    "print(matrix)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e9ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstem\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WordNetLemmatizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\nltk\\__init__.py:180\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download, download_shell\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Check if tkinter exists without importing it to avoid crashes after\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# forks on macOS. Only nltk.app, nltk.draw, and demo modules should\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# have top-level tkinter imports. See #2949 for more details.\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m importlib.util.find_spec(\u001b[33m\"\u001b[39m\u001b[33mtkinter\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\nltk\\downloader.py:2528\u001b[39m\n\u001b[32m   2518\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   2521\u001b[39m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[32m   2522\u001b[39m \u001b[38;5;66;03m# Main:\u001b[39;00m\n\u001b[32m   2523\u001b[39m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2526\u001b[39m \n\u001b[32m   2527\u001b[39m \u001b[38;5;66;03m# Aliases\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2528\u001b[39m _downloader = \u001b[43mDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2529\u001b[39m download = _downloader.download\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_shell\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\nltk\\downloader.py:503\u001b[39m, in \u001b[36mDownloader.__init__\u001b[39m\u001b[34m(self, server_index_url, download_dir)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# decide where we're going to save things to.\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._download_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     \u001b[38;5;28mself\u001b[39m._download_dir = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_download_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Genai_Projects\\ai_ecom_agent\\.venv\\Lib\\site-packages\\nltk\\downloader.py:1056\u001b[39m, in \u001b[36mDownloader.default_download_dir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1052\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# Check if we have sufficient permissions to install in a\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# variety of system-wide locations.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nltkdir \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m.path:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(nltkdir) \u001b[38;5;129;01mand\u001b[39;00m nltk.internals.is_writable(nltkdir):\n\u001b[32m   1058\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m nltkdir\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')        # for tokenization\n",
    "nltk.download('punkt_tab')    # fixes \"punkt_tab\" error in newer NLTK versions\n",
    "nltk.download('stopwords')    # for removing stopwords\n",
    "nltk.download('wordnet')      # for lemmatization\n",
    "nltk.download('omw-1.4') \n",
    "\n",
    "class NltkPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_data(self, text: str) -> str:\n",
    "        text = \"\" if text is None or (isinstance(text, float) and np.isnan(text)) else str(text)\n",
    "        text = text.lower()\n",
    "        # keep letters + spaces, drop everything else\n",
    "        text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X can be list/Series/ndarray; return list[str]\n",
    "        if isinstance(X, (pd.Series, pd.DataFrame)):\n",
    "            X = X.squeeze()\n",
    "        processed = []\n",
    "        for txt in X:\n",
    "            txt = self.clean_data(txt)\n",
    "            tokens = word_tokenize(txt)\n",
    "            tokens = [t for t in tokens if t not in self.stop_words]\n",
    "            tokens = [self.lemmatizer.lemmatize(t) for t in tokens]\n",
    "            processed.append(\" \".join(tokens))\n",
    "        return processed\n",
    "\n",
    "# -------- data --------\n",
    "df = pd.read_csv(r\"D:\\Genai_Projects\\ai_ecom_agent\\Data\\sentiment.csv\")\n",
    "X = df[\"text\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# -------- split --------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------- pipeline --------\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", NltkPreprocessor()),\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(class_weight=\"balanced\", max_iter=2000, solver=\"saga\"))\n",
    "])\n",
    "\n",
    "# -------- train --------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# -------- evaluate --------\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# -------- save --------\n",
    "with open(r\"D:\\Genai_Projects\\ai_ecom_agent\\models\\sentiment_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "print(\"ðŸŽ¯ Model pipeline saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5d02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ecom-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
